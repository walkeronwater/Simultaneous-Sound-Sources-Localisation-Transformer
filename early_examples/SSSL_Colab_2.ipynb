{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKIhOrdMId9e"
   },
   "source": [
    "### Extract binaural cues\n",
    "\n",
    "- IPD cues (similar as ITD (ambiguous at high frequencies))\n",
    "\n",
    "  arg(S_l/S_r)\n",
    "  \n",
    "  \n",
    "- Spectral cues (essentially tells about ILD cues)\n",
    "\n",
    "  do STFT and then convert it to magnitude and phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVBBvbOe3htZ"
   },
   "source": [
    "### Store arrays as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgqXpt5BypvL"
   },
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# h5f = h5py.File('/content/drive/My Drive/data.h5', 'w')\n",
    "# h5f.create_dataset('dataset_1', data=sigPairList[audioIndex])\n",
    "\n",
    "# with h5py.File('/content/drive/My Drive/data.h5', 'w') as hf:\n",
    "#     hf.create_dataset(\"dataset_1\",  data=sigPairList[audioIndex])\n",
    "\n",
    "for audioIndex in range(len(sigPairList)):\n",
    "    fileName=\"/content/drive/MyDrive/SSSL/npy/array\"+str(audioIndex)+\".npy\"\n",
    "    with open(fileName, 'wb') as f:\n",
    "        np.save(f, sigPairList[audioIndex])\n",
    "\n",
    "# fileName=\"/content/drive/MyDrive/array7.npy\"\n",
    "# with open(fileName, 'wb') as f:\n",
    "#     np.save(f, sigPairList[7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2usF9ViiSjF"
   },
   "source": [
    "#### Test: load from saved .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZYF3XYNgauw",
    "outputId": "c95ee237-a172-4e63-fbcc-61d7279285c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 23, 2, 16511)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sigPair = np.load('/content/drive/MyDrive/SSSL/np/array0.npy')\n",
    "print(sigPair.shape)\n",
    "sigPairList = []\n",
    "sigPairList.append(sigPair)\n",
    "# del sigPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDRHaNYQgqDc",
    "outputId": "2ee1e219-725c-4396-f9d6-dcbeb9b88101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   (210, 23, 2, 16511)\n",
      "1   (236, 23, 2, 16511)\n",
      "2   (311, 23, 2, 16511)\n",
      "3   (294, 23, 2, 16511)\n",
      "4   (269, 23, 2, 16511)\n",
      "5   (269, 23, 2, 16511)\n"
     ]
    }
   ],
   "source": [
    "sigPairList = []\n",
    "for i in range(0, 7):\n",
    "    sigPair = np.load('/content/drive/MyDrive/SSSL/np/array'+str(i)+'.npy')\n",
    "    # print(type(temp))\n",
    "    print(i,' ',sigPair.shape)\n",
    "    sigPairList.append(sigPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4gkrQumWTFA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x, y = np.load('/content/drive/MyDrive/SSSL/np/1.npz')\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHwr19_bId9f"
   },
   "outputs": [],
   "source": [
    "def cartesian2euler(val):\n",
    "    x = val.real\n",
    "    y = val.imag\n",
    "    \n",
    "    r = np.sqrt(x**2+y**2)\n",
    "\n",
    "    theta = np.arctan(\n",
    "        np.divide(y, x, where=x!=0)\n",
    "    )\n",
    "    # if x != 0:\n",
    "    #     theta = np.arctan(y/x)\n",
    "    # else:\n",
    "    #     theta = np.pi/2\n",
    "        \n",
    "    return normalise(r), normalise(theta)\n",
    "\n",
    "def calIPD(seqL, seqR):\n",
    "    temp = np.divide(seqL, seqR, out=np.zeros_like(seqL), where=seqR!=0)\n",
    "    ipd = np.arctan(np.divide(np.imag(temp), np.real(temp), out=np.zeros_like(np.real(temp)), where=np.real(temp)!=0))\n",
    "    return ipd\n",
    "\n",
    "def normalise(seq):\n",
    "    return seq/np.linalg.norm(seq)\n",
    "\n",
    "if False:\n",
    "    temp = np.array([[1,2,3],[1,2,3]])\n",
    "    print(normalise(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57ZriVENd_5-",
    "outputId": "d6654213-50e2-4204-f1a3-9319ad854b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 23, 2, 16511)\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "import random\n",
    "\n",
    "def binauralCues(sigPair, fs, valSNR):\n",
    "    f, t, Zxx = signal.stft(sigPair[0, 0, 0], fs, nperseg=1023)\n",
    "    # spectralCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (4,), dtype='float')\n",
    "    # ipdCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]), dtype='float')\n",
    "    cues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (5,), dtype='float')\n",
    "\n",
    "    del f, t, Zxx\n",
    "\n",
    "    for i in range(sigPair.shape[0]):\n",
    "        for locIndex in range(sigPair.shape[1]):\n",
    "            \n",
    "            f_l, t_l, Zxx_l = signal.stft(\n",
    "                sigPair[i, locIndex, 0] \n",
    "                # + noiseGenerator(sigPair[i, locIndex, 0], valSNR)\n",
    "                , fs, nperseg = 1023\n",
    "            )              \n",
    "                                          \n",
    "            f_r, t_r, Zxx_r = signal.stft(\n",
    "                sigPair[i, locIndex, 1] \n",
    "                # + noiseGenerator(sigPair[i, locIndex, 1], valSNR)\n",
    "                , fs, nperseg = 1023\n",
    "            )\n",
    "            # print(Zxx_l.shape)\n",
    "            # print(Zxx_r.shape)\n",
    "\n",
    "            r_l, theta_l = cartesian2euler(Zxx_l)\n",
    "            r_r, theta_r = cartesian2euler(Zxx_r)\n",
    "\n",
    "            # ipdCues[i, locIndex] = normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0)))\n",
    "            # spectralCues[i, locIndex] = np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "            cues[i, locIndex] = np.concatenate(\n",
    "                (np.expand_dims(\n",
    "                    normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0))), axis=-1\n",
    "                    ),\n",
    "                 np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "                 ),\n",
    "                 axis=-1\n",
    "            )\n",
    "    return cues\n",
    "    # return ipdCues, spectralCues\n",
    "\n",
    "print(sigPair.shape)\n",
    "cues = binauralCues(sigPair, 16000, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOH_lGBkf-O9",
    "outputId": "04e3cd74-bade-4cbb-b168-1306bba78702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 23, 34, 512, 5)\n",
      "(34, 512, 5)\n"
     ]
    }
   ],
   "source": [
    "print(cues.shape)\n",
    "\n",
    "root = \"/content/drive/MyDrive/SSSL/npy/temp\"\n",
    "# fileName=\"/content/drive/MyDrive/SSSL/npy/temp/temp2.npz\"\n",
    "\n",
    "data = np.zeros(cues.shape[2:])\n",
    "labels = np.zeros((1,))\n",
    "print(data.shape)\n",
    "\n",
    "audioCounter = 0\n",
    "counter = -1\n",
    "\n",
    "for i in range(cues.shape[0]):\n",
    "    for locIndex in range(cues.shape[1]):\n",
    "        data = cues[i,locIndex]\n",
    "        labels = locIndex\n",
    "\n",
    "        counter += 1\n",
    "        fileName = root + str(counter) + '.npz'\n",
    "        with open(fileName, 'wb') as f:\n",
    "            np.savez(f, data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkoTIgEbpPVS",
    "outputId": "6ffaf2d2-d528-4fd3-b739-b3a76f74932e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6187\n"
     ]
    }
   ],
   "source": [
    "root = \"/content/drive/MyDrive/SSSL/npy/\"\n",
    "print(len(os.listdir(root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpUj5Vy-Id9g"
   },
   "outputs": [],
   "source": [
    "# calculate spectral and IPD cues\n",
    "spectralCuesList = []\n",
    "ipdCuesList = []\n",
    "for audioIndex in range(len(sigPairList)):\n",
    "    spectralCues = np.zeros(sigPairList[audioIndex].shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (4,), dtype='float')\n",
    "    ipdCues = np.zeros(sigPairList[audioIndex].shape[:-2] + (Zxx.shape[1], Zxx.shape[0]), dtype='float')\n",
    "    print(\"IPD shape\", ipdCues.shape)\n",
    "    print(sigPairList[audioIndex].shape)\n",
    "\n",
    "    for i in range(sigPairList[audioIndex].shape[0]):\n",
    "        if i%100 == 1:\n",
    "            print(\"Sample \",i)\n",
    "        for locIndex in range(sigPairList[audioIndex].shape[1]):\n",
    "            f_l, t_l, Zxx_l = signal.stft(sigPairList[audioIndex][i, locIndex, 0], fs, nperseg=1023)\n",
    "            f_r, t_r, Zxx_r = signal.stft(sigPairList[audioIndex][i, locIndex, 1], fs, nperseg=1023)\n",
    "    #         print(Zxx_l.shape)\n",
    "            \n",
    "            ipdCues[i, locIndex] = normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0)))\n",
    "            \n",
    "            r_l, theta_l = cartesian2euler(Zxx_l)\n",
    "            r_r, theta_r = cartesian2euler(Zxx_r)\n",
    "            # temp = np.array([r_l, theta_l, r_r, theta_r])\n",
    "            # print(temp.shape)\n",
    "            spectralCues[i, locIndex] = np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "            \n",
    "            # for timeIndex in range(Zxx_l.shape[1]):\n",
    "            #     for freqIndex in range(Zxx_l.shape[0]):\n",
    "            #         r_l, theta_l = cartesian2euler(Zxx_l[freqIndex][timeIndex])\n",
    "            #         r_r, theta_r = cartesian2euler(Zxx_r[freqIndex][timeIndex])\n",
    "\n",
    "            #         spectralCues[i, locIndex, timeIndex, freqIndex] = np.array([r_l, theta_l, r_r, theta_r])\n",
    "                    # print(spectralCues[i, locIndex, timeIndex, freqIndex].shape)\n",
    "                    \n",
    "            \n",
    "    ipdCues = np.transpose(ipdCues, (1, 0, 2, 3))\n",
    "    spectralCues = np.transpose(spectralCues, (1, 0, 2, 3, 4))\n",
    "\n",
    "    ipdCuesList.append(ipdCues)\n",
    "    spectralCuesList.append(spectralCues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_VktGduId9h",
    "outputId": "95f008df-e60b-4ad4-a9ff-62c72bc152ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of feature matrices:\n",
      "(269, 23, 34, 512)\n",
      "(269, 23, 34, 512, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of feature matrices:\")\n",
    "print(ipdCues.shape)\n",
    "print(spectralCues.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76dwTXYjId9i"
   },
   "source": [
    "### Data visualisation [todo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QClIhLDLId9j"
   },
   "outputs": [],
   "source": [
    "# IPD visualisation\n",
    "\n",
    "# plt.plot(ipdCues[0,0,100:105,:])\n",
    "\n",
    "# plt.pcolormesh(t_l, f_l, np.abs(ipdCues[random.randint(0,186), 0]), shading='gouraud')\n",
    "# plt.title('IPD cues')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLwIU71jId9j"
   },
   "outputs": [],
   "source": [
    "# plt.pcolormesh(t, f, spectralCues[random.randint(0,186), 0, :,:,3], shading='gouraud')\n",
    "# plt.title('Spectral cues (left-ear)')\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYUyqLpXId9k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yt1BCwP-tzc"
   },
   "source": [
    "### Tensorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG3m652dId9k",
    "outputId": "0e397cd5-a4d1-4c0a-a342-bc26430a522c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cues shape:  (210, 23, 34, 512, 5)\n",
      "cues_ shape:  torch.Size([4830, 34, 512, 5])\n",
      "labels shape (210, 23, 1)\n",
      "labels_ shape:  torch.Size([4830, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cues_ = torch.from_numpy(cues.astype(np.float32))\n",
    "Nloc = cues_.shape[1]\n",
    "labels = np.zeros((cues_.shape[0], cues_.shape[1], 1)).astype(np.long)\n",
    "for i in range(cues.shape[0]):\n",
    "    for j in range(cues.shape[1]):\n",
    "        labels[i,j] = j\n",
    "\n",
    "labels_ = torch.from_numpy(labels)\n",
    "\n",
    "cues_ = cues_.reshape(cues_.shape[0] * cues_.shape[1], cues_.shape[2], cues_.shape[3], cues_.shape[4])\n",
    "labels_ = labels_.reshape(labels_.shape[0]*labels_.shape[1], 1)\n",
    "\n",
    "dataset_ = TensorDataset(cues_, labels_)\n",
    "\n",
    "\n",
    "print(\"cues shape: \",cues.shape)\n",
    "print(\"cues_ shape: \",cues_.shape)\n",
    "print(\"labels shape\",labels.shape)\n",
    "print(\"labels_ shape: \",labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vG1p-pKId9l",
    "outputId": "589abb00-90c6-4cf7-d5c1-bd8bf73fcc9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset separation:  2898 966 966\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "Ntrain = round(0.6*cues_.shape[0])\n",
    "if Ntrain % batch_size == 1:\n",
    "    Ntrain -=1\n",
    "Nvalid = round(0.2*cues_.shape[0])\n",
    "if Nvalid % batch_size == 1:\n",
    "    Nvalid -=1\n",
    "Ntest = cues_.shape[0] - Ntrain - Nvalid\n",
    "if Ntest % batch_size == 1:\n",
    "    Ntest -=1\n",
    "print(\"Dataset separation: \",Ntrain, Nvalid, Ntest)\n",
    "\n",
    "train, valid, test = torch.utils.data.random_split(dataset_, [Ntrain, Nvalid, Ntest], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(dataset=train, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset=valid, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test, batch_size=32, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L11DYF-3C93I"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model (for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inputShape, Nloc, isDebug):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.isDebug = isDebug\n",
    "\n",
    "        self.fc1 = nn.Linear(87040, Nloc)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.isDebug == True:\n",
    "            print(x.shape)\n",
    "        out = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        if self.isDebug == True:\n",
    "            print(out.shape)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        if self.isDebug == True:\n",
    "            print(out.shape)\n",
    "\n",
    "        return out\n",
    "\n",
    "if False:\n",
    "    tempInput = torch.from_numpy(np.random.rand(32,34,512,5).astype('float32'))\n",
    "    tempModel = MLP(tempInput.shape, 187, True)\n",
    "    tempOutput = tempModel(tempInput)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_N2X-4hspwT"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbUCgxrDAOmy"
   },
   "source": [
    "From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Sgw6yz8pId9m"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, freqSize, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.freqSize = freqSize\n",
    "        self.heads = heads\n",
    "        self.head_dim = freqSize // heads\n",
    "\n",
    "        # assert debug\n",
    "        assert (\n",
    "            self.head_dim * heads == freqSize\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        # obtain Q K V matrices by linear transformation\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, freqSize)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_time, value_freq = value.shape[1], value.shape[2]\n",
    "        key_time, key_freq = key.shape[1], key.shape[2]\n",
    "        query_time, query_freq = query.shape[1], query.shape[2]\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        value = value.reshape(N, value_time, self.heads, self.head_dim)\n",
    "        key = key.reshape(N, key_time, self.heads, self.head_dim)\n",
    "        query = query.reshape(N, query_time, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(value)  # (N, value_len, heads, head_dim)\n",
    "        keys = self.keys(key)  # (N, key_len, heads, head_dim)\n",
    "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.freqSize ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_time, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedSize, locSize):\n",
    "        super(Attention, self).__init__()\n",
    "        self.embedSize = embedSize\n",
    "\n",
    "        # obtain Q K V matrices by linear transformation\n",
    "        self.values = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.keys = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.queries = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.fc_out = nn.Linear(embedSize, locSize)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_time, value_freq = value.shape[1], value.shape[2]\n",
    "        key_time, key_freq = key.shape[1], key.shape[2]\n",
    "        query_time, query_freq = query.shape[1], query.shape[2]\n",
    "\n",
    "        values = self.values(value)  # (N, value_len, heads, head_dim)\n",
    "        keys = self.keys(key)  # (N, key_len, heads, head_dim)\n",
    "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
    "\n",
    "        energy = torch.einsum(\"ntqe,ntke->neqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embedSize ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"neqk,ntve->ntqe\", [attention, values]).reshape(\n",
    "            N, query_time, query_freq, self.embedSize\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, freqSize, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(freqSize, heads)\n",
    "        self.norm1 = nn.LayerNorm(freqSize)\n",
    "        self.norm2 = nn.LayerNorm(freqSize)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(freqSize, forward_expansion * freqSize),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * freqSize, freqSize),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        attention = self.attention(value, key, query)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        freqSize, # frequency bins\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.freqSize = freqSize\n",
    "        self.device = device\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    freqSize,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        timeSize, freqSize = x.shape[-2], x.shape[-1]\n",
    "        # positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(x)\n",
    "\n",
    "        # In the Encoder the query, key, value are all the same, it's in the\n",
    "        # decoder this will change. This might look a bit odd in this case.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SSSL(nn.Module):\n",
    "    def __init__(\n",
    "    self,\n",
    "    locSize,\n",
    "    timeSize, # time windows\n",
    "    freqSize, # frequency bins\n",
    "    num_layers,\n",
    "    heads,\n",
    "    device,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    isDebug\n",
    "    ):\n",
    "        super(SSSL, self).__init__()\n",
    "        self.encoder = Encoder(           \n",
    "            freqSize, # frequency bins\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.attention = Attention(5, locSize)\n",
    "        self.fcFreq = nn.Linear(freqSize, 1)\n",
    "        self.fcTime = nn.Linear(timeSize, 1)\n",
    "        self.isDebug = isDebug\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # self.softmaxLayer = nn.Softmax(dim = -1)\n",
    "    def forward(self, cues_):\n",
    "        enc_ipd = self.encoder(cues_[:,:,:,0])\n",
    "        if self.isDebug == True:\n",
    "            print(\"enc_ipd shape: \",enc_ipd.shape)\n",
    "        enc_slMag = self.encoder(cues_[:,:,:,1])\n",
    "        enc_slPhase = self.encoder(cues_[:,:,:,2])\n",
    "        enc_srMag = self.encoder(cues_[:,:,:,3])\n",
    "        enc_srPhase = self.encoder(cues_[:,:,:,4])\n",
    "        enc = torch.stack([enc_ipd, enc_slMag, enc_slPhase, enc_srMag, enc_srPhase])\n",
    "        # del enc_ipd, enc_slMag, enc_slPhase, enc_srMag, enc_srPhase\n",
    "        enc = enc.permute(1,2,3,0)\n",
    "        # encCat = torch.cat((enc_ipd, enc_slMag, enc_slPhase, enc_srMag, enc_srPhase), -1)\n",
    "        # print(enc.shape)\n",
    "        if self.isDebug == True:\n",
    "            print(\"enc shape: \",enc.shape)\n",
    "\n",
    "        attOut = self.attention(enc, enc, enc)\n",
    "        if self.isDebug == True:\n",
    "            print(\"attOut shape: \",attOut.shape)\n",
    "\n",
    "        out = self.fcFreq(attOut.permute(0,1,3,2))\n",
    "        out = out.squeeze(-1)\n",
    "        # out = self.dropout(out)\n",
    "\n",
    "        # out = torch.mean(attOut, -2)\n",
    "        # out = out.squeeze(-1)\n",
    "        if self.isDebug == True:\n",
    "            print(\"FC freq shape: \",out.shape)\n",
    "        \n",
    "        out = self.fcTime(out.permute(0, 2, 1))\n",
    "        out = out.squeeze(-1)\n",
    "        # out = self.dropout(out)\n",
    "\n",
    "        # out = torch.mean(out, -2)\n",
    "        # out = out.squeeze(-2)\n",
    "        if self.isDebug == True:\n",
    "            print(\"FC time shape: \",out.shape)\n",
    "\n",
    "\n",
    "        # out = self.softmaxLayer(out)\n",
    "        return out\n",
    "\n",
    "if False:\n",
    "    Nfreq = cues_.shape[2]\n",
    "    print(Nfreq)\n",
    "    Ntime = cues_.shape[1]\n",
    "    print(Ntime)\n",
    "    # Nloc = cues_.shape[0]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    numLayers = 3\n",
    "    model = SSSL(Nloc, Ntime, Nfreq, numLayers, 8, device, 4, 0, False).to(device)\n",
    "    testInput = cues_[-3:-1].to(device)\n",
    "    testLabel = labels_[-3:-1].to(device)\n",
    "    testOutput = model(testInput)\n",
    "    print(testInput.shape)\n",
    "    print(testOutput.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "9pgwebLU-EQi",
    "outputId": "58deb21d-44eb-4ddd-e56c-945005173061",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=device, abbreviated=False)\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVaR3Uuy7vPV"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGQ_Fp8_AdJn"
   },
   "source": [
    "Using Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSLB7RPj7wtF",
    "outputId": "c7cb6312-b92a-4be7-a1d6-28c0a278b354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "18\n",
      "cuda\n",
      "torch.Size([2, 18, 512])\n",
      "torch.Size([2, 23])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, freqSize, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.freqSize = freqSize\n",
    "        self.heads = heads\n",
    "        self.head_dim = freqSize // heads\n",
    "\n",
    "        # assert debug\n",
    "        assert (\n",
    "            self.head_dim * heads == freqSize\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        # obtain Q K V matrices by linear transformation\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, freqSize)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "        \n",
    "        value_time, value_freq = value.shape[1], value.shape[2]\n",
    "        key_time, key_freq = key.shape[1], key.shape[2]\n",
    "        query_time, query_freq = query.shape[1], query.shape[2]\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        value = value.reshape(N, value_time, self.heads, self.head_dim)\n",
    "        key = key.reshape(N, key_time, self.heads, self.head_dim)\n",
    "        query = query.reshape(N, query_time, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(value)  # (N, value_len, heads, head_dim)\n",
    "        keys = self.keys(key)  # (N, key_len, heads, head_dim)\n",
    "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.freqSize ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_time, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedSize, locSize):\n",
    "        super(Attention, self).__init__()\n",
    "        self.embedSize = embedSize\n",
    "\n",
    "        # obtain Q K V matrices by linear transformation\n",
    "        self.values = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.keys = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.queries = nn.Linear(embedSize, embedSize, bias=False)\n",
    "        self.fc_out = nn.Linear(embedSize, locSize)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_time, value_freq = value.shape[1], value.shape[2]\n",
    "        key_time, key_freq = key.shape[1], key.shape[2]\n",
    "        query_time, query_freq = query.shape[1], query.shape[2]\n",
    "\n",
    "        values = self.values(value)  # (N, value_len, heads, head_dim)\n",
    "        keys = self.keys(key)  # (N, key_len, heads, head_dim)\n",
    "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
    "\n",
    "        energy = torch.einsum(\"ntqe,ntke->neqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embedSize ** (1 / 2)), dim=3)\n",
    "\n",
    "        out = torch.einsum(\"neqk,ntve->ntqe\", [attention, values]).reshape(\n",
    "            N, query_time, query_freq, self.embedSize\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, freqSize, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(freqSize, heads)\n",
    "        self.norm1 = nn.LayerNorm(freqSize)\n",
    "        self.norm2 = nn.LayerNorm(freqSize)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(freqSize, forward_expansion * freqSize),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * freqSize, freqSize),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        attention = self.attention(value, key, query)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        freqSize, # frequency bins\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.freqSize = freqSize\n",
    "        self.device = device\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    freqSize,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        timeSize, freqSize = x.shape[-2], x.shape[-1]\n",
    "        # positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(x)\n",
    "\n",
    "        # In the Encoder the query, key, value are all the same, it's in the\n",
    "        # decoder this will change. This might look a bit odd in this case.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SSSL(nn.Module):\n",
    "    def __init__(\n",
    "    self,\n",
    "    locSize,\n",
    "    timeSize, # time windows\n",
    "    freqSize, # frequency bins\n",
    "    num_layers,\n",
    "    heads,\n",
    "    device,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    isDebug\n",
    "    ):\n",
    "        super(SSSL, self).__init__()\n",
    "\n",
    "        transformer_layers = nn.TransformerEncoderLayer(\n",
    "            freqSize, heads, 2048, dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(transformer_layers, num_layers)\n",
    "\n",
    "        # self.encoder = Encoder(           \n",
    "        #     freqSize, # frequency bins\n",
    "        #     num_layers,\n",
    "        #     heads,\n",
    "        #     device,\n",
    "        #     forward_expansion,\n",
    "        #     dropout,\n",
    "        # )\n",
    "        self.isDebug = isDebug\n",
    "        self.attention = Attention(5, locSize)\n",
    "        self.fcFreq = nn.Linear(freqSize, 1)\n",
    "        self.fcTime = nn.Linear(timeSize, 1)\n",
    "        # self.softmaxLayer = nn.Softmax(dim = -1)\n",
    "    def forward(self, ipd, slMag, slPhase, srMag, srPhase):\n",
    "        enc_ipd = self.encoder(ipd)\n",
    "        if self.isDebug == True:\n",
    "            print(\"enc_ipd shape: \",enc_ipd.shape)\n",
    "        enc_slMag = self.encoder(slMag)\n",
    "        enc_slPhase = self.encoder(slPhase)\n",
    "        enc_srMag = self.encoder(srMag)\n",
    "        enc_srPhase = self.encoder(srPhase)\n",
    "        enc = torch.stack([enc_ipd, enc_slMag, enc_slPhase, enc_srMag, enc_srPhase])\n",
    "        enc = enc.permute(1,2,3,0)\n",
    "        # encCat = torch.cat((enc_ipd, enc_slMag, enc_slPhase, enc_srMag, enc_srPhase), -1)\n",
    "        # print(enc.shape)\n",
    "\n",
    "        attOut = self.attention(enc, enc, enc)\n",
    "        # print(enc_ipd.shape)\n",
    "        if self.isDebug == True:\n",
    "            print(\"Attention output shape: \",attOut.shape)\n",
    "\n",
    "        out = self.fcFreq(attOut.permute(0,1,3,2))\n",
    "        out = out.squeeze(-1)\n",
    "        if self.isDebug == True:\n",
    "            print(\"FC freq shape: \",out.shape)\n",
    "\n",
    "        # out = torch.mean(attOut, -2)\n",
    "        # out = out.squeeze(-1)\n",
    "        # print(out.shape)\n",
    "        out = self.fcTime(out.permute(0,2,1))\n",
    "        out = out.squeeze(-1)\n",
    "        if self.isDebug == True:\n",
    "            print(\"FC time shape: \",out.shape)\n",
    "\n",
    "        # out = torch.mean(out, -2)\n",
    "        # out = out.squeeze(-2)\n",
    "\n",
    "\n",
    "        # out = self.softmaxLayer(out)\n",
    "        return out\n",
    "\n",
    "Nfreq = ipd_.shape[2]\n",
    "print(Nfreq)\n",
    "Ntime = ipd_.shape[1]\n",
    "print(Ntime)\n",
    "# Nloc = 187\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "numLayers = 6\n",
    "model = SSSL(Nloc, Ntime, Nfreq, numLayers, 8, device, 4, 0, False).to(device)\n",
    "testOut = model(ipd_[0:2].to(device),ipd_[0:2].to(device),ipd_[0:2].to(device),ipd_[0:2].to(device),ipd_[0:2].to(device))\n",
    "print(ipd_[0:2].shape)\n",
    "print(testOut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BlxkVzMGw_e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFRLFnSvy6Bl"
   },
   "source": [
    "### Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "0pyjBUGWId9m",
    "outputId": "57bea299-1777-4799-fc0f-c6dd167a78d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b6730764c3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# numLayers = 6\n",
    "# model = SSSL(Nloc, Ntime, Nfreq, numLayers, 8, device, 4, 0, False).to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "# batch_size = 32\n",
    "early_epoch = 100\n",
    "new_early_epoch = 0\n",
    "new_val_acc = 0.0\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=20, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"\\nEpoch %d\" % (epoch + 1))\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        length = len(train_loader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # print(\"Input shape: \",inputs.shape)\n",
    "        # print(\"Ouput shape: \", outputs.shape)\n",
    "        # print(\"Label shape: \", labels.shape)\n",
    "        loss = criterion(outputs, labels.squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "    print(\"correct: %d | total: %d\"\n",
    "        % (correct, total))\n",
    "    print('Training Loss: %.04f | Training Acc: %.4f%% '\n",
    "        % (sum_loss / (i + 1), 100.0 * correct / total))\n",
    "    \n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0.0\n",
    "    val_total = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels.squeeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    print('Val_Loss: %.04f | Val_Acc: %.4f%% '\n",
    "        % (val_loss, 100.0 * val_correct / val_total))\n",
    "\n",
    "    if (100.0 * val_correct / val_total <= new_val_acc):\n",
    "        new_early_epoch += 1\n",
    "    else:\n",
    "        new_val_acc = 100.0 * val_correct / val_total\n",
    "        new_early_epoch = 0\n",
    "    if (new_early_epoch >= early_epoch):\n",
    "        break\n",
    "\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, labels.squeeze(1))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "\n",
    "print('Test_Loss: %.04f | Test_Acc: %.4f%% '\n",
    "    % (test_loss, 100.0 * test_correct / test_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOHRlNk_qJK5"
   },
   "outputs": [],
   "source": [
    "# loss = criterion(outputs, labels)\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    print(i,' ',len(data),'',data[0].shape,' ',data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrZTixDgZE7T",
    "outputId": "d9fbf440-eb4e-4b46-ad55-94c8d22ab08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21, 21, 15,  8, 15, 22, 12, 22,  8, 22, 11, 12, 22, 21, 12, 20, 12, 20,\n",
      "        10, 10, 22, 10, 22, 11,  8,  4, 21, 15,  8,  4, 20, 20],\n",
      "       device='cuda:0')\n",
      "tensor([ 5, 16, 17, 14, 21, 22, 13, 12,  3,  8, 21,  1,  4, 12,  3, 16, 20,  9,\n",
      "        18,  0, 12,  8,  1, 21,  8,  9,  5,  6, 19,  5, 19, 12],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "print(labels.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43Do97mHxHrO"
   },
   "source": [
    "# Data Preparation\n",
    "- read audio files and HRIRs\n",
    "- convolution\n",
    "- add noise\n",
    "- extract binaural cues\n",
    "- save binaural cues with labels in disks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4IRDutO6U5-d"
   },
   "outputs": [],
   "source": [
    "# lib dependency\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3u-T3E_Id9K"
   },
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1bemuWIUdHkB"
   },
   "outputs": [],
   "source": [
    "isGoogleDrive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaT72KyAKzJs",
    "outputId": "39687b0d-5fac-4eb0-8062-0efded8c328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "if isGoogleDrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B87I4BOAId9O",
    "outputId": "6fcb75e1-4274-4261-94b4-8800240b603e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./HRTF\\IRC_1002\n",
      "1\n",
      "re.compile('IRC_\\\\d{4,4}')\n",
      "[1002]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "if isGoogleDrive:\n",
    "    path = \"./drive/MyDrive/SSSL/HRTF/IRC_*\"\n",
    "else:\n",
    "    path = \"./HRTF/IRC_*\"\n",
    "names = []\n",
    "names += glob(path)\n",
    "print(names[0])\n",
    "\n",
    "splitnames = [os.path.split(name) for name in names]\n",
    "print(len(splitnames))\n",
    "\n",
    "p = re.compile('IRC_\\d{4,4}')\n",
    "print(p)\n",
    "\n",
    "subjects = [int(name[4:8]) for base, name in splitnames \n",
    "                         if not (p.match(name[-8:]) is None)]\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlIzFtlTId9S"
   },
   "source": [
    "### load HRIRs from .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wb8V8wiAId9T"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "k = 0\n",
    "subject = subjects[k]\n",
    "\n",
    "for k in range(len(names)):\n",
    "    subject = subjects[k]\n",
    "    # filename = os.path.join(names[k], 'IRC_' + str(subject))\n",
    "    filename = os.path.join(names[k], 'COMPENSATED/MAT/HRIR/IRC_' + str(subject) + '_C_HRIR.mat')\n",
    "#     print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6O8ZsZ9Id9U"
   },
   "source": [
    "### Create labels (elevation, azimuth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsQWGV4sId9V",
    "outputId": "53108cc8-4d06-4a73-b56b-2c45d95d57e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'r_eq_hrir_S', 'l_eq_hrir_S'])\n",
      "[('elev_v', 'O'), ('azim_v', 'O'), ('type_s', 'O'), ('sampling_hz', 'O'), ('content_m', 'O')]\n",
      "locLabel shape:  (187, 2)  (order: elev, azim)\n",
      "hrirSet shape:  (187, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "m = loadmat(filename, struct_as_record=True)\n",
    "print(m.keys())\n",
    "print(m['l_eq_hrir_S'].dtype)\n",
    "\n",
    "l, r = m['l_eq_hrir_S'], m['r_eq_hrir_S']\n",
    "hrirSet_l = l['content_m'][0][0]\n",
    "hrirSet_r = r['content_m'][0][0]\n",
    "elev = l['elev_v'][0][0]\n",
    "azim = l['azim_v'][0][0]\n",
    "\n",
    "locLabel = np.hstack((elev, azim))\n",
    "print(\"locLabel shape: \", locLabel.shape, \" (order: elev, azim)\")\n",
    "# print(locLabel[0:5])\n",
    "\n",
    "# 0: left-ear 1: right-ear\n",
    "hrirSet = np.vstack((np.reshape(hrirSet_l, (1,) + hrirSet_l.shape),\n",
    "                          np.reshape(hrirSet_r, (1,) + hrirSet_r.shape)))\n",
    "hrirSet = np.transpose(hrirSet, (1,0,2))\n",
    "print(\"hrirSet shape: \", hrirSet.shape)\n",
    "\n",
    "if False:\n",
    "    for i in range(51,53):\n",
    "        plt.plot(hrirSet[i, 0])\n",
    "        plt.plot(hrirSet[i, 1])\n",
    "        plt.legend(['left','right'], loc='best')\n",
    "        plt.title('elevation: '+str(locLabel[i, 0])+' azimuth: '+str(locLabel[i, 1]))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q7Hrg3kId9X"
   },
   "source": [
    "### Convolve audio signals with left-ear and right-ear HRIR\n",
    "\n",
    "Input:\n",
    "\n",
    "- mono-track audio signal\n",
    "\n",
    "Output:\n",
    "\n",
    "- left-ear and right-ear time sequence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C7nJ7UuuJU7c"
   },
   "outputs": [],
   "source": [
    "# method to generate audio slices for a given length requirement\n",
    "# with a hardcoded power threshold\n",
    "def audioSliceGenerator(audioSeq, sampleRate, lenSliceInSec):\n",
    "    lenAudio = audioSeq.size\n",
    "    lenSlice = round(sampleRate * lenSliceInSec)\n",
    "    # audioSliceList = [range(lenSlice*i, lenSlice *(i+1)) for i in range(lenAudio//lenSlice)]\n",
    "    # print(len(audioSliceList))\n",
    "    # print(lenAudio//lenSlice)\n",
    "\n",
    "    audioSliceList = []\n",
    "    # threshold for spectrum power\n",
    "    for i in range(lenAudio//lenSlice):\n",
    "        sliced = audioSeq[lenSlice*i:lenSlice *(i+1)]\n",
    "        # print(\"slice power\", np.mean(np.power(sliced, 2)))\n",
    "        if np.mean(np.power(sliced, 2)) > 0.01:\n",
    "            audioSliceList.append(range(lenSlice*i, lenSlice *(i+1)))\n",
    "\n",
    "    return audioSliceList\n",
    "\n",
    "if False:\n",
    "    basedir = os.getcwd()\n",
    "    print(basedir)\n",
    "    # path = glob(os.path.join(basedir, \"/drive/MyDrive/SSSL/audio/*\"))\n",
    "    path = glob(os.path.join(\"/content/drive/MyDrive/SSSL/audio/*\"))\n",
    "    Naudio = len(path)\n",
    "    print(path)\n",
    "\n",
    "    data, sampleRate = sf.read(path[1])\n",
    "    print(data.shape)\n",
    "    temp2 = audioSliceGenerator(data, sampleRate, 0.5)\n",
    "    print(len(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lVh7J35eC8yQ"
   },
   "outputs": [],
   "source": [
    "# method to generate a sequence of noise for a given SNR\n",
    "def noiseGenerator(sigSeq, valSNR):\n",
    "    # assert debug\n",
    "    # assert (\n",
    "    #     sigSeq.shape[0] == 1\n",
    "    # ), \"Input data needs to be reshaped to (1, length of sequence)\"\n",
    "\n",
    "    sigSeqPower = 10*np.log10(np.mean(np.power(sigSeq, 2)))\n",
    "    noiseSeqPower = np.power(10, (sigSeqPower - valSNR)/10)\n",
    "    noiseSeq = np.random.normal(0, np.sqrt(noiseSeqPower), sigSeq.shape)\n",
    "    del sigSeqPower, noiseSeqPower\n",
    "    return noiseSeq\n",
    "\n",
    "'''def addNoise(sigPair):\n",
    "    valSNR = 1\n",
    "    # loop through all training examples\n",
    "    for i in range(sigPairList[0].shape[0]):\n",
    "        # loop through all locations\n",
    "        for locIndex in range(sigPairList[0].shape[1]):\n",
    "            noiseLeft = noiseGenerator(np.expand_dims(sigPairList[0][i,locIndex,0], axis=0), valSNR)\n",
    "            noiseRight = noiseGenerator(np.expand_dims(sigPairList[0][i,locIndex,1], axis=0), valSNR)'''\n",
    "\n",
    "if False:\n",
    "    temp = np.random.randn(1,150)\n",
    "    noiseGenerator(temp, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "24B-5uYP4Mhg"
   },
   "outputs": [],
   "source": [
    "# utility methods for binaural cue extraction\n",
    "def cartesian2euler(val):\n",
    "    x = val.real\n",
    "    y = val.imag\n",
    "    \n",
    "    r = np.sqrt(x**2+y**2)\n",
    "\n",
    "    theta = np.arctan(\n",
    "        np.divide(y, x, where=x!=0)\n",
    "    )\n",
    "    # if x != 0:\n",
    "    #     theta = np.arctan(y/x)\n",
    "    # else:\n",
    "    #     theta = np.pi/2\n",
    "        \n",
    "    return normalise(r), normalise(theta)\n",
    "\n",
    "def calIPD(seqL, seqR):\n",
    "    temp = np.divide(seqL, seqR, out=np.zeros_like(seqL), where=seqR!=0)\n",
    "    ipd = np.arctan(np.divide(np.imag(temp), np.real(temp), out=np.zeros_like(np.real(temp)), where=np.real(temp)!=0))\n",
    "    del temp\n",
    "    return ipd\n",
    "\n",
    "def normalise(seq):\n",
    "    return seq/np.linalg.norm(seq)\n",
    "\n",
    "if False:\n",
    "    temp = np.array([[1,2,3],[1,2,3]])\n",
    "    print(normalise(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HMlzqYXm4Mhi"
   },
   "outputs": [],
   "source": [
    "def binauralCues(sigPair, fs, valSNR):\n",
    "    if len(sigPair.shape) == 4:\n",
    "        print(\"Warning: high memory requirement in binauralCues()\")\n",
    "        f, t, Zxx = signal.stft(sigPair[0, 0, 0], fs, nperseg=1023)\n",
    "        # spectralCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (4,), dtype='float')\n",
    "        # ipdCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]), dtype='float')\n",
    "        cues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (5,), dtype='float')\n",
    "\n",
    "        del f, t, Zxx\n",
    "\n",
    "        for i in range(sigPair.shape[0]):\n",
    "            for locIndex in range(sigPair.shape[1]):\n",
    "                \n",
    "                _, _, Zxx_l = signal.stft(\n",
    "                    sigPair[i, locIndex, 0] \n",
    "                    # + noiseGenerator(sigPair[i, locIndex, 0], valSNR)\n",
    "                    , fs, nperseg = 1023\n",
    "                )              \n",
    "                                            \n",
    "                _, _, Zxx_r = signal.stft(\n",
    "                    sigPair[i, locIndex, 1] \n",
    "                    # + noiseGenerator(sigPair[i, locIndex, 1], valSNR)\n",
    "                    , fs, nperseg = 1023\n",
    "                )\n",
    "                # print(Zxx_l.shape)\n",
    "                # print(Zxx_r.shape)\n",
    "\n",
    "                r_l, theta_l = cartesian2euler(Zxx_l)\n",
    "                r_r, theta_r = cartesian2euler(Zxx_r)\n",
    "\n",
    "                # ipdCues[i, locIndex] = normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0)))\n",
    "                # spectralCues[i, locIndex] = np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "                cues[i, locIndex] = np.concatenate(\n",
    "                    (np.expand_dims(\n",
    "                        normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0))), axis=-1\n",
    "                        ),\n",
    "                    np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "                    ),\n",
    "                    axis=-1\n",
    "                )\n",
    "        \n",
    "        del Zxx_l, Zxx_r\n",
    "        return cues\n",
    "    elif len(sigPair.shape) == 2:\n",
    "        # f, t, Zxx = signal.stft(sigPair, fs, nperseg=1023)\n",
    "        # # spectralCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (4,), dtype='float')\n",
    "        # # ipdCues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]), dtype='float')\n",
    "        # cues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (5,), dtype='float')\n",
    "\n",
    "        # del f, t, Zxx\n",
    "\n",
    "        _, _, Zxx_l = signal.stft(\n",
    "            sigPair[0] \n",
    "            # + noiseGenerator(sigPair[i, locIndex, 0], valSNR)\n",
    "            , fs, nperseg = 1023\n",
    "        )              \n",
    "                                    \n",
    "        _, _, Zxx_r = signal.stft(\n",
    "            sigPair[1] \n",
    "            # + noiseGenerator(sigPair[i, locIndex, 1], valSNR)\n",
    "            , fs, nperseg = 1023\n",
    "        )\n",
    "        # print(Zxx_l.shape)\n",
    "        # print(Zxx_r.shape)\n",
    "\n",
    "        r_l, theta_l = cartesian2euler(Zxx_l)\n",
    "        r_r, theta_r = cartesian2euler(Zxx_r)\n",
    "        \n",
    "\n",
    "        # ipdCues[i, locIndex] = normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0)))\n",
    "        # spectralCues[i, locIndex] = np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "        cues = np.concatenate(\n",
    "            (np.expand_dims(\n",
    "                normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0))), axis=-1\n",
    "                ),\n",
    "            np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "            ),\n",
    "            axis=-1\n",
    "        )\n",
    "    \n",
    "        del Zxx_l, Zxx_r\n",
    "        return cues\n",
    "        \n",
    "\n",
    "if False:\n",
    "    # print(sigPair.shape) # sigPair shape: (Nclip, Nloc, 2, lenAfterConv)\n",
    "    sigPair = np.random.randn(2, 16511)\n",
    "    print(len(sigPair.shape))\n",
    "    cues = binauralCues(sigPair, 16000, 10) #cues shape: (Nclip, Nloc, Ntime, Nfreq, 5)\n",
    "    print(cues.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "5-2JAqTIId9Y",
    "outputId": "c8307ccb-de1e-460c-a097-82377a4c78d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mynam\\Documents\\GitHub\\Simultaneous-Sound-Localisation-Transformer\n",
      "['C:\\\\Users\\\\mynam\\\\Documents\\\\GitHub\\\\Simultaneous-Sound-Localisation-Transformer\\\\./audio\\\\music-fma-0001.wav']\n",
      "Number of audio files:  1\n",
      "(3488705,)\n",
      "Audio sample rate:  16000\n",
      "Number of samples:  210\n",
      "Initialise sigPair (210, 187, 2, 16511)\n"
     ]
    }
   ],
   "source": [
    "basedir = os.getcwd()\n",
    "print(basedir)\n",
    "# path = glob(os.path.join(basedir, \"/drive/MyDrive/SSSL/audio/*\"))\n",
    "path = glob(os.path.join(basedir, \"./audio/*\"))\n",
    "Naudio = len(path)\n",
    "print(path)\n",
    "print(\"Number of audio files: \",Naudio)\n",
    "\n",
    "# left-ear and right-ear signal pairs\n",
    "sigPairList = []\n",
    "# audioIndex = -1\n",
    "Nloc = hrirSet.shape[0]\n",
    "lenHRIR = hrirSet.shape[-1]\n",
    "valSNR = 10\n",
    "lenSliceInSec = 1\n",
    "\n",
    "\n",
    "\n",
    "for audioIndex in range(1): #len(path)\n",
    "    audioPath = path[audioIndex]\n",
    "    audioData, sampleRate = sf.read(audioPath)\n",
    "    print(audioData.shape)\n",
    "    print(\"Audio sample rate: \", sampleRate)\n",
    "\n",
    "    audioSliceList = audioSliceGenerator(audioData, sampleRate, lenSliceInSec)\n",
    "\n",
    "    sliceIndex = -1\n",
    "    Nsamples = len(audioSliceList)\n",
    "    print(\"Number of samples: \",Nsamples)\n",
    "    lenTruncate = len(audioSliceList[0])\n",
    "    lenAfterConv = lenHRIR+lenTruncate-1\n",
    "    \n",
    "    sigPair = np.zeros((Nsamples, Nloc, 2, lenAfterConv))\n",
    "    print(\"Initialise sigPair\", sigPair.shape)\n",
    "\n",
    "    for audioSlice in audioSliceList:\n",
    "        sliceIndex += 1\n",
    "\n",
    "        # if sliceIndex > 80:\n",
    "        #     break        \n",
    "\n",
    "        audio = audioData[audioSlice]\n",
    "        lenAfterConv = lenHRIR + audio.size - 1\n",
    "        # print(len(audioSlice))\n",
    "        # shape after convolution: 512 + audio length - 1\n",
    "\n",
    "        # hrirSet is of shape (187, 2, 512)\n",
    "        for locIndex in range(Nloc): \n",
    "            sigLeft = np.convolve(audio, hrirSet[locIndex, 0])\n",
    "            sigRight = np.convolve(audio, hrirSet[locIndex, 1])\n",
    "\n",
    "            sigPair[sliceIndex, locIndex, 0] = sigLeft.reshape(1, sigLeft.shape[0])\n",
    "            sigPair[sliceIndex, locIndex, 1] = sigRight.reshape(1, sigRight.shape[0])\n",
    "\n",
    "    del sigLeft, sigRight\n",
    "\n",
    "    fileCount = -1\n",
    "    for i in range(sigPair.shape[0]):\n",
    "        # if i > 80:\n",
    "        #     break\n",
    "        for locIndex in range(Nloc):\n",
    "            fileCount += 1\n",
    "\n",
    "            cues = binauralCues(sigPair[i, locIndex], 16000, valSNR)\n",
    "            label = np.array([locIndex])\n",
    "            \n",
    "            # fileName=\"/content/drive/MyDrive/SSSL/np/\"+str(fileCount)+\".npz\"\n",
    "            # with open(fileName, 'wb') as f:\n",
    "            #     np.savez(f, cues, label)\n",
    "\n",
    "            cues = np.expand_dims(cues, axis=0)\n",
    "            label = np.expand_dims(label, axis=0)\n",
    "            \n",
    "            h5FileName = './h5/'+'music'+str(audioIndex)+'_loc'+str(Nloc)+'_SNR'+str(valSNR)+'.h5'\n",
    "            \n",
    "            if fileCount == 0:\n",
    "                with h5py.File(h5FileName, 'w') as hf:\n",
    "                    hf.create_dataset('data', data=cues, maxshape=(None, 34, 512, 5), chunks=True)\n",
    "                    hf.create_dataset('labels', data=label, maxshape=(None, 1), chunks=True)\n",
    "            else:\n",
    "                with h5py.File(h5FileName, 'a') as hf:\n",
    "                    hf['data'].resize((hf['data'].shape[0] + cues.shape[0]), axis = 0)\n",
    "                    hf['data'][-cues.shape[0]:] = cues\n",
    "\n",
    "                    hf['labels'].resize((hf['labels'].shape[0] + label.shape[0]), axis = 0)\n",
    "                    hf['labels'][-cues.shape[0]:] = label\n",
    "\n",
    "            # if fileCount >=2:\n",
    "            #     raise SystemExit(\"Stop right there!\")\n",
    "            del cues, label\n",
    "\n",
    "    # raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "    del sigPair\n",
    "\n",
    "    # sigPairList.append(sigPair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THnvpmzSFDj8",
    "outputId": "833a768a-3221-4dc6-cee7-e4efb0d18396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data', 'labels']>\n",
      "(39270, 34, 512, 5)\n",
      "(39270, 1)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./h5/music0_loc187_SNR10.h5', 'r') as hf:\n",
    "    print(hf.keys())\n",
    "    print(hf['data'].shape)\n",
    "    print(hf['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgy93jZLouY6"
   },
   "outputs": [],
   "source": [
    "print(len(sigPairList))\n",
    "print(sigPairList[0].shape)\n",
    "\n",
    "\n",
    "if False:\n",
    "    noiseSeq = noiseGenerator(sigPairList[0][0,0,0], valSNR=20)\n",
    "    \n",
    "    plt.plot(sigPairList[0][0,0,0])\n",
    "    plt.title(\"signal\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(noiseSeq)\n",
    "    plt.title(\"noise\")\n",
    "    plt.show()\n",
    "\n",
    "    sampleRate = 16000\n",
    "\n",
    "    f, t, Zxx = signal.stft(sigPairList[0][0,0,0], sampleRate, nperseg=1023)\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx), shading='gouraud')\n",
    "    plt.title('STFT Magnitude of signal')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n",
    "\n",
    "    f, t, Zxx = signal.stft(noiseSeq, sampleRate, nperseg=1023)\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx), shading='gouraud')\n",
    "    plt.title('STFT Magnitude of noise')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaH678TLId9d"
   },
   "source": [
    "### Windowed FFT\n",
    "\n",
    "Input:\n",
    "\n",
    "- left-ear and right-ear time sequences\n",
    "\n",
    "Output:\n",
    "\n",
    "- left-ear and right-ear time-varying spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDFIgS41Id9d"
   },
   "outputs": [],
   "source": [
    "# visualise left-ear and right-ear signal pairs and their spectrogram\n",
    "\n",
    "print(sigPairList[0].shape)\n",
    "randomExample = 0\n",
    "randomLoc = random.randint(0, sigPairList[0].shape[1] - 1)\n",
    "plt.plot(sigPairList[0][randomExample, randomLoc, 0])\n",
    "plt.plot(sigPairList[0][randomExample, randomLoc, 1])\n",
    "plt.title('Time sequence pairs for location '+str(randomLoc))\n",
    "plt.legend(['left','right'])\n",
    "plt.show()\n",
    "\n",
    "fs = 16000 #sampleRate\n",
    "print(fs)\n",
    "\n",
    "f, t, Zxx = signal.stft(sigPairList[0][randomExample, randomLoc, 0], fs, nperseg=1023)\n",
    "print(Zxx.shape)\n",
    "\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), shading='gouraud')\n",
    "plt.title('STFT Magnitude (L/R) for location '+str(randomLoc))\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4OKf9T1s6U3"
   },
   "source": [
    "# Training\n",
    "- load binaural cues and corresponding labels from disks\n",
    "- tensorisation\n",
    "- network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ks4GAV0fWlbr"
   },
   "outputs": [],
   "source": [
    "# lib dependency\n",
    "from scipy import signal\n",
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.utils.data\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYTKr-TLtDsJ",
    "outputId": "2ee1e219-725c-4396-f9d6-dcbeb9b88101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   (210, 23, 2, 16511)\n",
      "1   (236, 23, 2, 16511)\n",
      "2   (311, 23, 2, 16511)\n",
      "3   (294, 23, 2, 16511)\n",
      "4   (269, 23, 2, 16511)\n",
      "5   (269, 23, 2, 16511)\n"
     ]
    }
   ],
   "source": [
    "sigPairList = []\n",
    "for i in range(0, 7):\n",
    "    sigPair = np.load('/content/drive/MyDrive/SSSL/npy/array'+str(i)+'.npy')\n",
    "    print(i,' ',sigPair.shape)\n",
    "    sigPairList.append(sigPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_T3cwqDWF59"
   },
   "outputs": [],
   "source": [
    "def cartesian2euler(val):\n",
    "    x = val.real\n",
    "    y = val.imag\n",
    "    \n",
    "    r = np.sqrt(x**2+y**2)\n",
    "\n",
    "    theta = np.arctan(\n",
    "        np.divide(y, x, where=x!=0)\n",
    "    )\n",
    "    # if x != 0:\n",
    "    #     theta = np.arctan(y/x)\n",
    "    # else:\n",
    "    #     theta = np.pi/2\n",
    "        \n",
    "    return normalise(r), normalise(theta)\n",
    "\n",
    "def calIPD(seqL, seqR):\n",
    "    temp = np.divide(seqL, seqR, out=np.zeros_like(seqL), where=seqR!=0)\n",
    "    ipd = np.arctan(np.divide(np.imag(temp), np.real(temp), out=np.zeros_like(np.real(temp)), where=np.real(temp)!=0))\n",
    "    return ipd\n",
    "\n",
    "def normalise(seq):\n",
    "    return np.log10(seq)/np.linalg.norm(seq)\n",
    "\n",
    "# method to generate a sequence of noise for a given SNR\n",
    "def noiseGenerator(sigSeq, valSNR):\n",
    "    # assert debug\n",
    "    # assert (\n",
    "    #     sigSeq.shape[0] == 1\n",
    "    # ), \"Input data needs to be reshaped to (1, length of sequence)\"\n",
    "\n",
    "    sigSeqPower = 10*np.log10(np.mean(np.power(sigSeq, 2)))\n",
    "    noiseSeqPower = np.power(10, (sigSeqPower - valSNR)/10)\n",
    "    noiseSeq = np.random.normal(0, np.sqrt(noiseSeqPower), sigSeq.shape)\n",
    "    del sigSeqPower, noiseSeqPower\n",
    "    return noiseSeq\n",
    "\n",
    "\n",
    "def binauralCues(sigPair, fs, valSNR):\n",
    "    f, t, Zxx = signal.stft(sigPair[0, 0, 0], fs, nperseg=1023)\n",
    "    cues = np.zeros(sigPair.shape[:-2] + (Zxx.shape[1], Zxx.shape[0]) + (5,), dtype='float')\n",
    "\n",
    "    del f, t, Zxx\n",
    "\n",
    "    for i in range(sigPair.shape[0]):\n",
    "        for locIndex in range(sigPair.shape[1]):\n",
    "            \n",
    "            f_l, t_l, Zxx_l = signal.stft(\n",
    "                sigPair[i, locIndex, 0] \n",
    "                + noiseGenerator(sigPair[i, locIndex, 0], valSNR)\n",
    "                , fs, nperseg = 1023\n",
    "            )              \n",
    "                                          \n",
    "            f_r, t_r, Zxx_r = signal.stft(\n",
    "                sigPair[i, locIndex, 1] \n",
    "                + noiseGenerator(sigPair[i, locIndex, 1], valSNR)\n",
    "                , fs, nperseg = 1023\n",
    "            )\n",
    "            # print(Zxx_l.shape)\n",
    "            # print(Zxx_r.shape)\n",
    "\n",
    "            r_l, theta_l = cartesian2euler(Zxx_l)\n",
    "            r_r, theta_r = cartesian2euler(Zxx_r)\n",
    "\n",
    "            cues[i, locIndex] = np.concatenate(\n",
    "                (np.expand_dims(\n",
    "                    normalise(np.transpose(calIPD(Zxx_l, Zxx_r), (1, 0))), axis=-1\n",
    "                    ),\n",
    "                 np.transpose(np.array([r_l, theta_l, r_r, theta_r]), (2, 1 ,0))\n",
    "                 ),\n",
    "                 axis=-1\n",
    "            )\n",
    "    return cues\n",
    "\n",
    "# class Trainer()\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_epochs = 100,\n",
    "#         learning_rate = 1e-4,\n",
    "#         batch_size = 32,\n",
    "#         early_epoch = 100,\n",
    "#         new_early_epoch = 0,\n",
    "#         new_val_loss = 0.0,\n",
    "#     ):\n",
    "\n",
    "def ModelTrainer(model, dataset_):\n",
    "    batch_size = 32\n",
    "    Ntrain = round(0.6*cues_.shape[0])\n",
    "    if Ntrain % batch_size == 1:\n",
    "        Ntrain -=1\n",
    "    Nvalid = round(0.2*cues_.shape[0])\n",
    "    if Nvalid % batch_size == 1:\n",
    "        Nvalid -=1\n",
    "    Ntest = cues_.shape[0] - Ntrain - Nvalid\n",
    "    if Ntest % batch_size == 1:\n",
    "        Ntest -=1\n",
    "    print(\"Dataset separation: \",Ntrain, Nvalid, Ntest)\n",
    "\n",
    "    train, valid, test = torch.utils.data.random_split(dataset_, [Ntrain, Nvalid, Ntest], generator=torch.Generator().manual_seed(42))\n",
    "    train_loader = DataLoader(dataset=train, batch_size=32, shuffle=True, num_workers=0)\n",
    "    valid_loader = DataLoader(dataset=valid, batch_size=32, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "    # training phase settings\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    early_epoch = 100\n",
    "    new_early_epoch = 0\n",
    "    new_val_acc = 0.0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=20, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"\\nEpoch %d\" % (epoch + 1))\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            length = len(train_loader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # print(\"Input shape: \",inputs.shape)\n",
    "            # print(\"Ouput shape: \", outputs.shape)\n",
    "            # print(\"Label shape: \", labels.shape)\n",
    "            loss = criterion(outputs, labels.squeeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "        print(\"correct:\",correct)\n",
    "        print(\"total\",total)\n",
    "        print('Training Loss: %.04f | Training Acc: %.4f%% '\n",
    "            % (sum_loss / (i + 1), 100.0 * correct / total))\n",
    "        \n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0.0\n",
    "        val_total = 0.0\n",
    "\n",
    "        # validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valid_loader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels.squeeze(1))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print('Val_Loss: %.04f | Val_Acc: %.4f%% '\n",
    "            % (val_loss, 100.0 * val_correct / val_total))\n",
    "\n",
    "        if (100.0 * val_correct / val_total <= new_val_acc):\n",
    "            new_early_epoch += 1\n",
    "        else:\n",
    "            new_val_acc = 100.0 * val_correct / val_total\n",
    "            new_early_epoch = 0\n",
    "        if (new_early_epoch >= early_epoch):\n",
    "            break\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0.0\n",
    "    test_total = 0.0\n",
    "    # test phase\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            test_loss = criterion(outputs, labels.squeeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "\n",
    "    print('Test_Loss: %.04f | Test_Acc: %.4f%% '\n",
    "        % (test_loss, 100.0 * test_correct / test_total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDtmRNWJ5Hj4"
   },
   "outputs": [],
   "source": [
    "temp = np.random.randn(35,512)\n",
    "tempLabel = np.random.randint(0,187,size=(1,))\n",
    "\n",
    "# print(tempLabel)\n",
    "\n",
    "fileName=\"/content/drive/MyDrive/SSSL/np/0.npz\"\n",
    "with open(fileName, 'wb') as f:\n",
    "    # np.savez(f, temp)\n",
    "    np.savez(f, temp, tempLabel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn3TrJHYwslQ"
   },
   "source": [
    "### Loading binaural cues  from disk and load randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "mihITnvqmGr-",
    "outputId": "56873b75-2791-4665-bd60-78d446825d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['music0_loc187_SNR10.h5', 'music0_loc187_SNR10.zip']\n",
      "39270\n",
      "1228\n",
      "batch  0 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  1 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  2 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  3 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  4 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  5 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  6 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  7 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n",
      "1228\n",
      "batch  8 torch.Size([32, 34, 512, 5]) torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e6df9000d0bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e6df9000d0bb>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "        # self.root = '/content/drive/MyDrive/SSSL/h5/dataset_24loc.h5'\n",
    "        self.root = './h5'\n",
    "        self.dset = os.listdir(self.root)\n",
    "        print(self.dset)\n",
    "        with h5py.File('./h5/music0_loc187_SNR10.h5', 'r') as hf:\n",
    "            self.dset_len = len(hf[\"data\"])\n",
    "\n",
    "        # with h5py.File(h5FileName, 'a') as hf:\n",
    "        # hf['data'].resize((hf['data'].shape[0] + cues.shape[0]), axis = 0)\n",
    "        # hf['data'][-cues.shape[0]:] = cues\n",
    "\n",
    "        # hf['labels'].resize((hf['labels'].shape[0] + label.shape[0]), axis = 0)\n",
    "        # hf['labels'][-cues.shape[0]:] = label\n",
    "\n",
    "    # def __getindex__(self, idx):\n",
    "    #     return load_file(self.data_files[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        self.h5_file = h5py.File('./h5/music0_loc187_SNR10.h5', 'r')\n",
    "        self.data = self.h5_file['data']\n",
    "        self.labels = self.h5_file['labels']\n",
    "        \n",
    "        data, labels = np.array(self.data[idx]), np.array(self.labels[idx])\n",
    "\n",
    "        data = torch.from_numpy(data.astype(np.float32))\n",
    "        labels = torch.from_numpy(labels.astype(np.long))\n",
    "        return data, labels\n",
    "\n",
    "\n",
    "dset = MyDataset()\n",
    "loader = DataLoader(dset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "print(dset.__len__())\n",
    "# test\n",
    "if True:\n",
    "    for idx, x in enumerate(loader, 0):\n",
    "        print(len(loader))\n",
    "        print(\"batch \", idx, x[0].shape, x[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lUY6yHA6s_3"
   },
   "outputs": [],
   "source": [
    "data = np.random.random(size = (1000,20))\n",
    "label = np.random.randint(0, 187, (1000,))\n",
    "\n",
    "with h5py.File('/content/drive/MyDrive/SSSL/h5/data2.h5', 'w') as hf:\n",
    "    hf.create_dataset('data', data=data, maxshape=(None, None), chunks=True)\n",
    "    hf.create_dataset('labels', data=label, maxshape=(None,), chunks=True)\n",
    "\n",
    "\n",
    "# with h5py.File('/content/drive/MyDrive/SSSL/h5/data2.h5', 'a') as hf:\n",
    "#     print(hf['dataset_1'].shape)\n",
    "#     hf[\"dataset_1\"].resize((hf[\"dataset_1\"].shape[0] + d2.shape[0]), axis = 0)\n",
    "    \n",
    "#     hf[\"dataset_1\"][-d2.shape[0]:] = d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-UX_W3_nVCO",
    "outputId": "ac5a11f6-576b-4ca0-9cda-3aa6a7086dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data', 'labels']>\n",
      "(1000, 20)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/content/drive/MyDrive/SSSL/h5/data2.h5', 'r') as hf:\n",
    "    print(hf.keys())\n",
    "    print(hf['data'].shape)\n",
    "    print(hf['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzkqEW0fRQKO"
   },
   "outputs": [],
   "source": [
    "# !pip install PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# 1-BXp_4d_bIKMRJ4tI-NIA9Z1aFJkuPkL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5b8aXgfSbBM"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1-BXp_4d_bIKMRJ4tI-NIA9Z1aFJkuPkL\"})   # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('dataset_24loc.h5')        # replace the file name with your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4XF8OagBgvyY",
    "outputId": "fd1a3a85-e753-47a0-f29d-5de9b65924e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset separation:  23562 7854 7854\n",
      "cpu\n",
      "\n",
      "Epoch 1\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-79741a382747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#             print(\"1 epoch ==\",length,\" batches\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mynam\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e6df9000d0bb>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lenDataset = dset.__len__()\n",
    "\n",
    "batch_size = 32\n",
    "Ntrain = round(0.6*lenDataset)\n",
    "if Ntrain % batch_size == 1:\n",
    "    Ntrain -=1\n",
    "Nvalid = round(0.2*lenDataset)\n",
    "if Nvalid % batch_size == 1:\n",
    "    Nvalid -=1\n",
    "Ntest = lenDataset - Ntrain - Nvalid\n",
    "if Ntest % batch_size == 1:\n",
    "    Ntest -=1\n",
    "print(\"Dataset separation: \",Ntrain, Nvalid, Ntest)\n",
    "\n",
    "train, valid, test = torch.utils.data.random_split(dset, [Ntrain, Nvalid, Ntest], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(dataset=train, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset=valid, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "if True:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    numLayers = 3\n",
    "#     model = SSSL(187, 34, 512, numLayers, 8, device, 4, 0, False).to(device)\n",
    "    model = MLP((34, 512, 5), 187, False).to(device)\n",
    "\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    early_epoch = 100\n",
    "    new_early_epoch = 0\n",
    "    new_val_acc = 0.0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=20, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"\\nEpoch %d\" % (epoch + 1))\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            length = len(train_loader)\n",
    "#             print(\"1 epoch ==\",length,\" batches\")\n",
    "            inputs, labels = data\n",
    "            '''inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # print(\"Input shape: \",inputs.shape)\n",
    "            # print(\"Ouput shape: \", outputs.shape)\n",
    "            # print(\"Label shape: \", labels.shape)\n",
    "            loss = criterion(outputs, labels.squeeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "        print(\"correct:\",correct)\n",
    "        print(\"total\",total)\n",
    "        print('Training Loss: %.04f | Training Acc: %.4f%% '\n",
    "            % (sum_loss / (i + 1), 100.0 * correct / total))\n",
    "        \n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0.0\n",
    "        val_total = 0.0\n",
    "\n",
    "        # validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valid_loader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels.squeeze(1))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print('Val_Loss: %.04f | Val_Acc: %.4f%% '\n",
    "            % (val_loss, 100.0 * val_correct / val_total))\n",
    "\n",
    "        if (100.0 * val_correct / val_total <= new_val_acc):\n",
    "            new_early_epoch += 1\n",
    "        else:\n",
    "            new_val_acc = 100.0 * val_correct / val_total\n",
    "            new_early_epoch = 0\n",
    "        if (new_early_epoch >= early_epoch):\n",
    "            break\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0.0\n",
    "    test_total = 0.0\n",
    "    # test phase\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            test_loss = criterion(outputs, labels.squeeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "\n",
    "    print('Test_Loss: %.04f | Test_Acc: %.4f%% '\n",
    "        % (test_loss, 100.0 * test_correct / test_total))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNYy3GT2s-W7",
    "outputId": "57b95a32-ab25-49ed-dfdd-f718c2752ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   (210, 23, 2, 16511)\n",
      "1   (236, 23, 2, 16511)\n",
      "2   (311, 23, 2, 16511)\n",
      "torch.Size([757, 23, 34, 512, 5])\n",
      "cues shape:  (757, 23, 34, 512, 5)\n",
      "cues_ shape:  torch.Size([17411, 34, 512, 5])\n",
      "labels shape:  (757, 23, 1)\n",
      "labels_ shape:  torch.Size([17411, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ModelTrainer(model, dataset_):\n",
    "    batch_size = 32\n",
    "    Ntrain = round(0.6*cues_.shape[0])\n",
    "    if Ntrain % batch_size == 1:\n",
    "        Ntrain -=1\n",
    "    Nvalid = round(0.2*cues_.shape[0])\n",
    "    if Nvalid % batch_size == 1:\n",
    "        Nvalid -=1\n",
    "    Ntest = cues_.shape[0] - Ntrain - Nvalid\n",
    "    if Ntest % batch_size == 1:\n",
    "        Ntest -=1\n",
    "    print(\"Dataset separation: \",Ntrain, Nvalid, Ntest)\n",
    "\n",
    "    train, valid, test = torch.utils.data.random_split(dataset_, [Ntrain, Nvalid, Ntest], generator=torch.Generator().manual_seed(42))\n",
    "    train_loader = DataLoader(dataset=train, batch_size=32, shuffle=True, num_workers=0)\n",
    "    valid_loader = DataLoader(dataset=valid, batch_size=32, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "    # training phase settings\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    early_epoch = 100\n",
    "    new_early_epoch = 0\n",
    "    new_val_acc = 0.0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=20, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"\\nEpoch %d\" % (epoch + 1))\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            length = len(train_loader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # print(\"Input shape: \",inputs.shape)\n",
    "            # print(\"Ouput shape: \", outputs.shape)\n",
    "            # print(\"Label shape: \", labels.shape)\n",
    "            loss = criterion(outputs, labels.squeeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "        print(\"correct:\",correct)\n",
    "        print(\"total\",total)\n",
    "        print('Training Loss: %.04f | Training Acc: %.4f%% '\n",
    "            % (sum_loss / (i + 1), 100.0 * correct / total))\n",
    "        \n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0.0\n",
    "        val_total = 0.0\n",
    "\n",
    "        # validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valid_loader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels.squeeze(1))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print('Val_Loss: %.04f | Val_Acc: %.4f%% '\n",
    "            % (val_loss, 100.0 * val_correct / val_total))\n",
    "\n",
    "        if (100.0 * val_correct / val_total <= new_val_acc):\n",
    "            new_early_epoch += 1\n",
    "        else:\n",
    "            new_val_acc = 100.0 * val_correct / val_total\n",
    "            new_early_epoch = 0\n",
    "        if (new_early_epoch >= early_epoch):\n",
    "            break\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0.0\n",
    "    test_total = 0.0\n",
    "    # test phase\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels.long()).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            test_loss = criterion(outputs, labels.squeeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels.squeeze(1).data).sum().item()\n",
    "\n",
    "    print('Test_Loss: %.04f | Test_Acc: %.4f%% '\n",
    "        % (test_loss, 100.0 * test_correct / test_total))\n",
    "\n",
    "\n",
    "if True:\n",
    "    cuesList = []\n",
    "    for i in range(0,3): # lenAudio = 7\n",
    "        sigPair = np.load('/content/drive/MyDrive/SSSL/npy/array'+str(i)+'.npy')\n",
    "        print(i,' ',sigPair.shape)\n",
    "\n",
    "        cues = binauralCues(sigPair, 16000, valSNR=20)\n",
    "        del sigPair\n",
    "        cuesList.append(cues)\n",
    "        # del cues\n",
    "\n",
    "cues = np.concatenate((cuesList[0], cuesList[1], cuesList[2]),axis=0)\n",
    "del cuesList\n",
    "\n",
    "# tensorisation\n",
    "cues_ = torch.from_numpy(cues.astype(np.float32))\n",
    "print(cues_.shape)\n",
    "Nloc = cues_.shape[1]\n",
    "labels = np.zeros((cues_.shape[0], cues_.shape[1], 1)).astype(np.long)\n",
    "for i in range(cues.shape[0]):\n",
    "    for j in range(cues.shape[1]):\n",
    "        labels[i,j] = j\n",
    "\n",
    "labels_ = torch.from_numpy(labels)\n",
    "\n",
    "cues_ = cues_.reshape(cues_.shape[0] * cues_.shape[1], cues_.shape[2], cues_.shape[3], cues_.shape[4])\n",
    "labels_ = labels_.reshape(labels_.shape[0] * labels_.shape[1], 1)\n",
    "\n",
    "print(\"cues shape: \",cues.shape)\n",
    "print(\"cues_ shape: \",cues_.shape)\n",
    "print(\"labels shape: \",labels.shape)\n",
    "print(\"labels_ shape: \",labels_.shape)\n",
    "\n",
    "del cues, labels\n",
    "\n",
    "# create tensorDataset\n",
    "dataset_ = TensorDataset(cues_, labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WbMnjy8Y3bFK",
    "outputId": "94acfbd2-35c2-45f8-e778-45afedaa1c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17411\n",
      "Dataset separation:  10447 3482 3482\n",
      "\n",
      "Epoch 1\n",
      "correct: 498.0\n",
      "total 10447.0\n",
      "Training Loss: 3.1355 | Training Acc: 4.7669% \n",
      "Val_Loss: 3.1353 | Val_Acc: 5.6864% \n",
      "\n",
      "Epoch 2\n",
      "correct: 978.0\n",
      "total 10447.0\n",
      "Training Loss: 2.9104 | Training Acc: 9.3615% \n",
      "Val_Loss: 2.7625 | Val_Acc: 11.5738% \n",
      "\n",
      "Epoch 3\n",
      "correct: 1503.0\n",
      "total 10447.0\n",
      "Training Loss: 2.5956 | Training Acc: 14.3869% \n",
      "Val_Loss: 2.3915 | Val_Acc: 17.1740% \n",
      "\n",
      "Epoch 4\n",
      "correct: 2083.0\n",
      "total 10447.0\n",
      "Training Loss: 2.3817 | Training Acc: 19.9387% \n",
      "Val_Loss: 2.3113 | Val_Acc: 19.2993% \n",
      "\n",
      "Epoch 5\n",
      "correct: 2949.0\n",
      "total 10447.0\n",
      "Training Loss: 2.1030 | Training Acc: 28.2282% \n",
      "Val_Loss: 1.8239 | Val_Acc: 32.1080% \n",
      "\n",
      "Epoch 6\n",
      "correct: 4051.0\n",
      "total 10447.0\n",
      "Training Loss: 1.7890 | Training Acc: 38.7767% \n",
      "Val_Loss: 1.7702 | Val_Acc: 36.4159% \n",
      "\n",
      "Epoch 7\n",
      "correct: 5289.0\n",
      "total 10447.0\n",
      "Training Loss: 1.3710 | Training Acc: 50.6270% \n",
      "Val_Loss: 1.0561 | Val_Acc: 48.0758% \n",
      "\n",
      "Epoch 8\n",
      "correct: 7007.0\n",
      "total 10447.0\n",
      "Training Loss: 0.9058 | Training Acc: 67.0719% \n",
      "Val_Loss: 0.6349 | Val_Acc: 60.6835% \n",
      "\n",
      "Epoch 9\n",
      "correct: 8809.0\n",
      "total 10447.0\n",
      "Training Loss: 0.4811 | Training Acc: 84.3209% \n",
      "Val_Loss: 1.9514 | Val_Acc: 62.3492% \n",
      "\n",
      "Epoch 10\n",
      "correct: 9799.0\n",
      "total 10447.0\n",
      "Training Loss: 0.2194 | Training Acc: 93.7973% \n",
      "Val_Loss: 1.0961 | Val_Acc: 67.6623% \n",
      "\n",
      "Epoch 11\n",
      "correct: 9896.0\n",
      "total 10447.0\n",
      "Training Loss: 0.2193 | Training Acc: 94.7258% \n",
      "Val_Loss: 0.8959 | Val_Acc: 67.9207% \n",
      "\n",
      "Epoch 12\n",
      "correct: 10331.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0537 | Training Acc: 98.8896% \n",
      "Val_Loss: 1.7400 | Val_Acc: 68.3515% \n",
      "\n",
      "Epoch 13\n",
      "correct: 10238.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0747 | Training Acc: 97.9994% \n",
      "Val_Loss: 1.3043 | Val_Acc: 66.8294% \n",
      "\n",
      "Epoch 14\n",
      "correct: 10227.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0888 | Training Acc: 97.8941% \n",
      "Val_Loss: 2.0411 | Val_Acc: 67.8346% \n",
      "\n",
      "Epoch 15\n",
      "correct: 10193.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0891 | Training Acc: 97.5687% \n",
      "Val_Loss: 1.3584 | Val_Acc: 68.7249% \n",
      "\n",
      "Epoch 16\n",
      "correct: 10406.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0216 | Training Acc: 99.6075% \n",
      "Val_Loss: 0.4558 | Val_Acc: 69.6726% \n",
      "\n",
      "Epoch 17\n",
      "correct: 10297.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0562 | Training Acc: 98.5642% \n",
      "Val_Loss: 2.3967 | Val_Acc: 63.6129% \n",
      "\n",
      "Epoch 18\n",
      "correct: 10213.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0969 | Training Acc: 97.7601% \n",
      "Val_Loss: 0.6791 | Val_Acc: 63.3831% \n",
      "\n",
      "Epoch 19\n",
      "correct: 10422.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0168 | Training Acc: 99.7607% \n",
      "Val_Loss: 1.0549 | Val_Acc: 70.0460% \n",
      "\n",
      "Epoch 20\n",
      "correct: 10429.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0091 | Training Acc: 99.8277% \n",
      "Val_Loss: 0.9271 | Val_Acc: 67.7484% \n",
      "\n",
      "Epoch 21\n",
      "correct: 10403.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0219 | Training Acc: 99.5788% \n",
      "Val_Loss: 2.2918 | Val_Acc: 65.2786% \n",
      "\n",
      "Epoch 22\n",
      "correct: 10085.0\n",
      "total 10447.0\n",
      "Training Loss: 0.1612 | Training Acc: 96.5349% \n",
      "Val_Loss: 1.0488 | Val_Acc: 70.7065% \n",
      "\n",
      "Epoch 23\n",
      "correct: 10417.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0170 | Training Acc: 99.7128% \n",
      "Val_Loss: 1.6070 | Val_Acc: 69.3567% \n",
      "\n",
      "Epoch 24\n",
      "correct: 10437.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0087 | Training Acc: 99.9043% \n",
      "Val_Loss: 2.3753 | Val_Acc: 67.8059% \n",
      "\n",
      "Epoch 25\n",
      "correct: 10359.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0338 | Training Acc: 99.1577% \n",
      "Val_Loss: 2.6948 | Val_Acc: 69.6726% \n",
      "\n",
      "Epoch 26\n",
      "correct: 10374.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0278 | Training Acc: 99.3012% \n",
      "Val_Loss: 0.7499 | Val_Acc: 66.3986% \n",
      "\n",
      "Epoch 27\n",
      "correct: 10221.0\n",
      "total 10447.0\n",
      "Training Loss: 0.1078 | Training Acc: 97.8367% \n",
      "Val_Loss: 2.5572 | Val_Acc: 68.8685% \n",
      "\n",
      "Epoch 28\n",
      "correct: 10405.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0201 | Training Acc: 99.5980% \n",
      "Val_Loss: 1.0731 | Val_Acc: 70.1895% \n",
      "\n",
      "Epoch 29\n",
      "correct: 10440.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0052 | Training Acc: 99.9330% \n",
      "Val_Loss: 1.1258 | Val_Acc: 70.4767% \n",
      "\n",
      "Epoch 30\n",
      "correct: 10440.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0045 | Training Acc: 99.9330% \n",
      "Val_Loss: 1.7109 | Val_Acc: 72.2860% \n",
      "\n",
      "Epoch 31\n",
      "correct: 10446.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0025 | Training Acc: 99.9904% \n",
      "Val_Loss: 0.6566 | Val_Acc: 70.4193% \n",
      "\n",
      "Epoch 32\n",
      "correct: 10385.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0201 | Training Acc: 99.4065% \n",
      "Val_Loss: 1.2633 | Val_Acc: 70.3619% \n",
      "\n",
      "Epoch 33\n",
      "correct: 10128.0\n",
      "total 10447.0\n",
      "Training Loss: 0.1468 | Training Acc: 96.9465% \n",
      "Val_Loss: 1.2904 | Val_Acc: 70.7926% \n",
      "\n",
      "Epoch 34\n",
      "correct: 10431.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0125 | Training Acc: 99.8468% \n",
      "Val_Loss: 1.3419 | Val_Acc: 74.0666% \n",
      "\n",
      "Epoch 35\n",
      "correct: 10444.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0029 | Training Acc: 99.9713% \n",
      "Val_Loss: 1.3181 | Val_Acc: 72.5158% \n",
      "\n",
      "Epoch 36\n",
      "correct: 10446.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0012 | Training Acc: 99.9904% \n",
      "Val_Loss: 1.1437 | Val_Acc: 72.1424% \n",
      "\n",
      "Epoch 37\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0007 | Training Acc: 100.0000% \n",
      "Epoch    37: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Val_Loss: 1.5695 | Val_Acc: 71.2809% \n",
      "\n",
      "Epoch 38\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0005 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.3605 | Val_Acc: 71.2522% \n",
      "\n",
      "Epoch 39\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0004 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.2108 | Val_Acc: 71.3670% \n",
      "\n",
      "Epoch 40\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0003 | Training Acc: 100.0000% \n",
      "Val_Loss: 0.5976 | Val_Acc: 70.9937% \n",
      "\n",
      "Epoch 41\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0003 | Training Acc: 100.0000% \n",
      "Val_Loss: 0.9798 | Val_Acc: 70.9937% \n",
      "\n",
      "Epoch 42\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0002 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.7231 | Val_Acc: 70.4767% \n",
      "\n",
      "Epoch 43\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0002 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.3041 | Val_Acc: 70.4767% \n",
      "\n",
      "Epoch 44\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0002 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.9559 | Val_Acc: 70.5629% \n",
      "\n",
      "Epoch 45\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.6487 | Val_Acc: 70.0747% \n",
      "\n",
      "Epoch 46\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.6321 | Val_Acc: 69.9024% \n",
      "\n",
      "Epoch 47\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.3868 | Val_Acc: 69.9598% \n",
      "\n",
      "Epoch 48\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.6970 | Val_Acc: 69.7013% \n",
      "\n",
      "Epoch 49\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 5.1686 | Val_Acc: 69.5003% \n",
      "\n",
      "Epoch 50\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0001 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.6613 | Val_Acc: 69.1844% \n",
      "\n",
      "Epoch 51\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 0.4197 | Val_Acc: 69.2418% \n",
      "\n",
      "Epoch 52\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.9843 | Val_Acc: 68.7536% \n",
      "\n",
      "Epoch 53\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 0.7041 | Val_Acc: 68.8397% \n",
      "\n",
      "Epoch 54\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.9970 | Val_Acc: 68.8397% \n",
      "\n",
      "Epoch 55\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.8189 | Val_Acc: 68.0930% \n",
      "\n",
      "Epoch 56\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.6995 | Val_Acc: 68.3802% \n",
      "\n",
      "Epoch 57\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 4.6911 | Val_Acc: 67.5474% \n",
      "\n",
      "Epoch 58\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.5427 | Val_Acc: 67.7197% \n",
      "\n",
      "Epoch 59\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 0.9620 | Val_Acc: 67.6335% \n",
      "\n",
      "Epoch 60\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.4419 | Val_Acc: 67.4325% \n",
      "\n",
      "Epoch 61\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.1074 | Val_Acc: 67.2889% \n",
      "\n",
      "Epoch 62\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.1344 | Val_Acc: 67.2315% \n",
      "\n",
      "Epoch 63\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.9531 | Val_Acc: 67.1166% \n",
      "\n",
      "Epoch 64\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 4.9329 | Val_Acc: 66.9156% \n",
      "\n",
      "Epoch 65\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.7410 | Val_Acc: 66.5997% \n",
      "\n",
      "Epoch 66\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.3035 | Val_Acc: 66.5709% \n",
      "\n",
      "Epoch 67\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 1.6182 | Val_Acc: 66.3986% \n",
      "\n",
      "Epoch 68\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.9825 | Val_Acc: 66.2263% \n",
      "\n",
      "Epoch 69\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 5.7936 | Val_Acc: 66.1401% \n",
      "\n",
      "Epoch 70\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.0108 | Val_Acc: 65.9966% \n",
      "\n",
      "Epoch 71\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.9557 | Val_Acc: 65.7955% \n",
      "\n",
      "Epoch 72\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Epoch    72: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Val_Loss: 2.0638 | Val_Acc: 65.8242% \n",
      "\n",
      "Epoch 73\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.6905 | Val_Acc: 65.7668% \n",
      "\n",
      "Epoch 74\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.9972 | Val_Acc: 65.4796% \n",
      "\n",
      "Epoch 75\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 5.3538 | Val_Acc: 65.6519% \n",
      "\n",
      "Epoch 76\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.4781 | Val_Acc: 65.6806% \n",
      "\n",
      "Epoch 77\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.5321 | Val_Acc: 65.5370% \n",
      "\n",
      "Epoch 78\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.2055 | Val_Acc: 65.5945% \n",
      "\n",
      "Epoch 79\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 4.6178 | Val_Acc: 65.7381% \n",
      "\n",
      "Epoch 80\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.8025 | Val_Acc: 65.3360% \n",
      "\n",
      "Epoch 81\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 6.6463 | Val_Acc: 65.5370% \n",
      "\n",
      "Epoch 82\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 3.7652 | Val_Acc: 65.5083% \n",
      "\n",
      "Epoch 83\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n",
      "Val_Loss: 2.3168 | Val_Acc: 65.3935% \n",
      "\n",
      "Epoch 84\n",
      "correct: 10447.0\n",
      "total 10447.0\n",
      "Training Loss: 0.0000 | Training Acc: 100.0000% \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d12a4f3c1d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSSL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-88a6b5188efa>\u001b[0m in \u001b[0;36mModelTrainer\u001b[0;34m(model, dataset_)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(dataset_))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SSSL(23, 34, 512, 3, 8, device, 4, 0, False).to(device)\n",
    "ModelTrainer(model, dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSUXs2iLWJ-z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "t3u-T3E_Id9K",
    "NlIzFtlTId9S",
    "u6O8ZsZ9Id9U",
    "pVBBvbOe3htZ",
    "76dwTXYjId9i",
    "qVaR3Uuy7vPV"
   ],
   "history_visible": true,
   "machine_shape": "hm",
   "name": "SSSL_Colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
